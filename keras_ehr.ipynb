{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOmXUMktrCqz"
   },
   "source": [
    "# **Machine Learning Lesson 1: Building a risk prediction tool for electronic health record data**\n",
    "* Code adapted from University of Florida course *Biomedical Data Science*, College of Engineering (Parisa Rashidi 2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6MVt0bkArtGu"
   },
   "source": [
    "At the end of this lesson, you will be able to:\n",
    "\n",
    "* Get familar with steps of developing an Artificial intelligence (AI) model\n",
    "* Execute visualization code for a real-world AI model in electronic health record (EHR) dataset\n",
    "* Interpret the result of AI model\n",
    "\n",
    "In this notebook, we will implement two classifiers to predict the risk of a given surgical patient to develop postoperative Acute Kidney Injury (AKI) from a structured dataset of medical predictors. \n",
    "\n",
    "## 1. Motivation\n",
    "\n",
    "Predicting postoperative complications has the potential to inform shared decisions regarding the appropriateness of surgical procedures, targeted risk-reduction strategies, and postoperative resource use. Cognitive and judgment errors are major sources of potentially preventable complications. For example, underestimation of the risk of complications may be associated with postoperative undertriage of high-risk patients to general wards rather than intensive care units (ICUs) and an increased prevalence of hospital mortality.\n",
    "\n",
    "High-performance data-based clinical decision support has the potential to mitigate harm from cognitive errors occurring when estimating the risk of postoperative complications. All patients have a unique risk profile that is specific to their demographic characteristics, comorbid conditions, physiological reserve, planned surgical procedure, and surgeonâ€™s skill; clinicians have had mediocre performance in estimating risk probabilities. Decision support tools are intended to augment these\n",
    "estimations, but many are hindered by time-consuming manual data entry requirements and lack of integration with clinical workflow. AI predictive models using automated EHR data inputs may be able to mitigate these challenges.\n",
    "\n",
    "In this notebook, we will focus on postoperative AKI complication and develop machine learning (ML) models to predict the risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Lifecycle of ML\n",
    "\n",
    "Following are the major steps that are involved in the ML lifecycle.\n",
    "<img src=\"ML.png\" alt=\"ML lifecycle\" width=\"800\" height=\"800\">\n",
    "\n",
    "### Data extraction and processing\n",
    "\n",
    "Relevant data must be extracted. For example, all revelant laboratory values and vital signs. Data quality and conformation to modeling requirements must be ensured through data preprocessing. For example, fixing the missing data, removing the unwanted outlier, and encoding the categorical data.\n",
    "\n",
    "### Model development\n",
    "\n",
    "Using various ML algorithms, we will develop a model on a training cohort. During the model refinement stage, model parameters (such as weights and biases) are altered to optimize the associations between inputs and outputs. \n",
    "\n",
    "### Evaluation and Intepretation\n",
    "\n",
    "Once a ML model is trained, we evaluate the end result on validation dataset to see how well the model performed or how reliable it is. Multiple performance metrics such as sensitivity, specificity will be evaluated. Model explainability or interpretability can be explored at this stage to elucidate the relative importance of inputs. For example, lower eGFR and higher systolic blood pressure associated with outcome.\n",
    "\n",
    "### Deployment\n",
    "\n",
    "ML model deployment is the process of placing a finished ML model into the live environment, such as creating a web service or mobile application for prediction. It is imperative that the performance of an established model is continually monitored in prospective deployment to safeguard against population drifts or data shifts that may result in deteriorating performance over time.\n",
    "\n",
    "### Optimization\n",
    "\n",
    "When new data sources are coming in or necessary steps for upgrading the performance of the ML model should be taken, we need to optimize the model by reinstructing the ML model in production.\n",
    "\n",
    "In this notebook, we will only focus on the first three phases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and explore dataset \n",
    "\n",
    "For this projetc, we will be using the EHR dataset which contains 10,000 surgical patients.\n",
    "\n",
    "* Each patient profile will contain the demographic variables (age, sex, race etc.), scheduled surgery related variables (doctor, scheduled room, scheduld anesthesia type), admission characteristic variables (emergent, transfer from other hospital etc.), neighborhood charactersitic variables (zip, rural, distance_from_shands etc.), comorbidity variables (diabetes, cancer, hypertension etc.), medications taken within one year before scheduled surgery (aspirin, diuretics, statins etc.), and laboratory measurements taken within 7 days or 8 to 365 days before scheduled surgery (hemoglobin, white blood cell count etc.)\n",
    "* The outcome is postoperative AKI. In other words the model will predict 'yes' or 'no' for each of surgical patient.\n",
    "\n",
    "The dataset includes a CSV file that provides the medical predictors and labels for each patient. We start with loading dataset into a Pandas dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>race</th>\n",
       "      <th>language</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>county</th>\n",
       "      <th>attend_doc</th>\n",
       "      <th>sched_room</th>\n",
       "      <th>...</th>\n",
       "      <th>serum_ca_min_0_7</th>\n",
       "      <th>serum_ca_max_0_7</th>\n",
       "      <th>serum_ca_avg_0_7</th>\n",
       "      <th>serum_ca_var_0_7</th>\n",
       "      <th>count_serum_can_0_7</th>\n",
       "      <th>serum_anion_gap_avg_0_7</th>\n",
       "      <th>count_serum_anion_gapn_0_7</th>\n",
       "      <th>ckd</th>\n",
       "      <th>egfr</th>\n",
       "      <th>aki_surg_disch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>NON-HISPANIC</td>\n",
       "      <td>AA</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>DIVORCED</td>\n",
       "      <td>NEVER</td>\n",
       "      <td>Duval</td>\n",
       "      <td>888339</td>\n",
       "      <td>NT OR 09</td>\n",
       "      <td>...</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>0.0</td>\n",
       "      <td>missing</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No CKD</td>\n",
       "      <td>No eGFR</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>MALE</td>\n",
       "      <td>NON-HISPANIC</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>CURRENT</td>\n",
       "      <td>Polk</td>\n",
       "      <td>737072</td>\n",
       "      <td>NT OR 12</td>\n",
       "      <td>...</td>\n",
       "      <td>8.6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0.6533333333333339</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No CKD</td>\n",
       "      <td>95.5001555676506</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>NON-HISPANIC</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>NEVER</td>\n",
       "      <td>Alachua</td>\n",
       "      <td>984724</td>\n",
       "      <td>HVN OR 14</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No CKD</td>\n",
       "      <td>No eGFR</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>MALE</td>\n",
       "      <td>NON-HISPANIC</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>FORMER</td>\n",
       "      <td>Alachua</td>\n",
       "      <td>322319</td>\n",
       "      <td>ST OR 14</td>\n",
       "      <td>...</td>\n",
       "      <td>8.7</td>\n",
       "      <td>10.3</td>\n",
       "      <td>9.233333333333333</td>\n",
       "      <td>0.2824242424242431</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>No CKD</td>\n",
       "      <td>89.14911769245806</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>MALE</td>\n",
       "      <td>NON-HISPANIC</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>NEVER</td>\n",
       "      <td>Union</td>\n",
       "      <td>85055</td>\n",
       "      <td>NT OR 05</td>\n",
       "      <td>...</td>\n",
       "      <td>8.7</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.025</td>\n",
       "      <td>0.1392857142857141</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>No CKD</td>\n",
       "      <td>120.95438867365282</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id     sex     ethnicity   race language marital_status  \\\n",
       "0           0  FEMALE  NON-HISPANIC     AA  ENGLISH       DIVORCED   \n",
       "1           1    MALE  NON-HISPANIC  WHITE  ENGLISH        MARRIED   \n",
       "2           2  FEMALE  NON-HISPANIC  WHITE  ENGLISH        MARRIED   \n",
       "3           3    MALE  NON-HISPANIC  WHITE  ENGLISH        MARRIED   \n",
       "4           4    MALE  NON-HISPANIC  WHITE  ENGLISH         SINGLE   \n",
       "\n",
       "  smoking_status   county  attend_doc sched_room  ... serum_ca_min_0_7  \\\n",
       "0          NEVER    Duval      888339   NT OR 09  ...          missing   \n",
       "1        CURRENT     Polk      737072   NT OR 12  ...              8.6   \n",
       "2          NEVER  Alachua      984724  HVN OR 14  ...             10.0   \n",
       "3         FORMER  Alachua      322319   ST OR 14  ...              8.7   \n",
       "4          NEVER    Union       85055   NT OR 05  ...              8.7   \n",
       "\n",
       "  serum_ca_max_0_7   serum_ca_avg_0_7    serum_ca_var_0_7 count_serum_can_0_7  \\\n",
       "0          missing            missing             missing                 0.0   \n",
       "1             10.0                9.3  0.6533333333333339                 4.0   \n",
       "2             10.0               10.0                 0.0                 2.0   \n",
       "3             10.3  9.233333333333333  0.2824242424242431                12.0   \n",
       "4              9.6              9.025  0.1392857142857141                 8.0   \n",
       "\n",
       "  serum_anion_gap_avg_0_7 count_serum_anion_gapn_0_7     ckd  \\\n",
       "0                 missing                        0.0  No CKD   \n",
       "1                     9.0                        2.0  No CKD   \n",
       "2                     7.0                        1.0  No CKD   \n",
       "3                     8.5                        6.0  No CKD   \n",
       "4                    12.6                        5.0  No CKD   \n",
       "\n",
       "                 egfr aki_surg_disch  \n",
       "0             No eGFR            0.0  \n",
       "1    95.5001555676506            0.0  \n",
       "2             No eGFR            0.0  \n",
       "3   89.14911769245806            1.0  \n",
       "4  120.95438867365282            0.0  \n",
       "\n",
       "[5 rows x 139 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the outcome and check the prevalence of postoperative AKI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    8364\n",
      "1.0    1636\n",
      "Name: aki_surg_disch, dtype: int64\n",
      "prevalence 0.1636\n"
     ]
    }
   ],
   "source": [
    "print(df['aki_surg_disch'].value_counts())\n",
    "prevalence = sum(df['aki_surg_disch'] == 1) / len(df['aki_surg_disch']) \n",
    "print('prevalence', prevalence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data preprocessing\n",
    "\n",
    "Before training, you will first clean the dataset to ensure it conform the modeling requirement. Several steps might be involved:\n",
    "\n",
    "* Removing outliers\n",
    "* Fixing missingess\n",
    "* Transforming the dataset (encode the categorical variables etc.)\n",
    "* Feature Scaling\n",
    "\n",
    "Regarding the outlier removing, one common approach is to remove observations that fall in top and bottom x% of the distribution. In provided dataset, we have removed observations in top/bottom 1% of the distribution.\n",
    "\n",
    "### 4.1 Fixing missingness\n",
    "\n",
    "Missing data are common in routinely collected health data and often missingness is informative. For example, laboratory data are often missing for intentional (e.g., the patient does not need certain laboratory tests) or unintentional (e.g., lack of routine checkup or follow-up) reasons. Estimation bias and model performance from missingness can be mitigated using imputation methods.\n",
    "\n",
    "One simple but effective imputation approach is replacing missing values for each individual value by using a quantitative attribute or qualitative attribute of all the non-missing values. Methods such as replacing missing values with mode, mean or median of the available values are often used. \n",
    "\n",
    "Let's look at one variable 'serum_ca_min_0_7' (minimum serum calcium with 0-7 days before scheduled surgery start time). This variable contains missing value marked with 'missing'. Let's impute those missing values with median of the available values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---before imputation---\n",
      "0    missing\n",
      "1        8.6\n",
      "2       10.0\n",
      "3        8.7\n",
      "4        8.7\n",
      "Name: serum_ca_min_0_7, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('---before imputation---')\n",
    "print(df['serum_ca_min_0_7'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first convert those cells with 'missing' vlaue into empty cells. Then we check the median value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     NaN\n",
      "1     8.6\n",
      "2    10.0\n",
      "3     8.7\n",
      "4     8.7\n",
      "Name: serum_ca_min_0_7, dtype: float64\n",
      "median value 9.1\n"
     ]
    }
   ],
   "source": [
    "##we first remove 'missing' and convert all available values to numeric values. If â€˜coerceâ€™, then invalid parsing will be set as NaN\n",
    "df['serum_ca_min_0_7'] = pd.to_numeric(df['serum_ca_min_0_7'], errors='coerce')\n",
    "print(df['serum_ca_min_0_7'].head())\n",
    "\n",
    "##calculate median value\n",
    "val = df['serum_ca_min_0_7'].median()\n",
    "print('median value', val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use fillna() function to fill all empty cells with median value. We will add one more column 'imputed_serum_ca_min_0_7' to save the imputed value for comparison.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---after imputation with median value---\n",
      "0     9.1\n",
      "1     8.6\n",
      "2    10.0\n",
      "3     8.7\n",
      "4     8.7\n",
      "Name: imputed_serum_ca_min_0_7, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df['imputed_serum_ca_min_0_7'] = df['serum_ca_min_0_7'].fillna(val)\n",
    "print('---after imputation with median value---')\n",
    "print(df['imputed_serum_ca_min_0_7'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the missing value has been replace to median value 9.1. Let's try imputing the missing values with mean function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean value 9.00409984871407\n",
      "---after imputation with mean value---\n",
      "0     9.0041\n",
      "1     8.6000\n",
      "2    10.0000\n",
      "3     8.7000\n",
      "4     8.7000\n",
      "Name: imputed_serum_ca_min_0_7, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "###Todo: change 'X' to 'mean' to calculate the mean value\n",
    "# val = df['serum_ca_min_0_7'].X()\n",
    "val = df['serum_ca_min_0_7'].mean() # New\n",
    "print('mean value', val)\n",
    "df['imputed_serum_ca_min_0_7'] = df['serum_ca_min_0_7'].fillna(val)\n",
    "print('---after imputation with mean value---')\n",
    "print(df['imputed_serum_ca_min_0_7'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to this simple imputation, there are also other popular imputation approaches, such as k-Nearest neighbors (KNN) and multiple imputation by chained equation (MICE). For more information, you can refer to [KNN](https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html#examples-using-sklearn-impute-knnimputer) and [MICE](https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html#sklearn.impute.IterativeImputer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Transforming the dataset\n",
    "\n",
    "EHR data contains both categorical values and numeric values. However, most Python models now only accept numeric values. We need to convert all categorical values to numeric values.\n",
    "\n",
    "Let's look at one variable 'sex' which contains two levels: 'FEMALE' and 'MALE'. For these binary values, we can transform these values to numeric values by simply replacing them with 0 and 1 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---before tranformation---\n",
      "['FEMALE' 'MALE']\n",
      "---after tranformation---\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print('---before tranformation---')\n",
    "print(df['sex'].unique())\n",
    "##let us replace 'FEMALE' with 0 and 'MALE' with 1\n",
    "df['sex'] = df['sex'].replace({'FEMALE' : 0, 'MALE' : 1})\n",
    "print('---after tranformation---')\n",
    "print(df['sex'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try another variable 'anesthesia_type' which contains two levels: 'GENERAL'and 'LOCAL/REGIONAL'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---before tranformation---\n",
      "['GENERAL' 'LOCAL/REGIONAL']\n",
      "---after tranformation---\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print('---before tranformation---')\n",
    "print(df['anesthesia_type'].unique())\n",
    "##Todo: let us replace 'X' and 'Y' with two 'anesthesia_type' levels 'GENERAL'and 'LOCAL/REGIONAL' respectively\n",
    "# df['anesthesia_type'] = df['anesthesia_type'].replace({X : 0, Y : 1})\n",
    "df['anesthesia_type'] = df['anesthesia_type'].replace({'GENERAL' : 0, 'LOCAL/REGIONAL' : 1}) #New\n",
    "print('---after tranformation---')\n",
    "print(df['anesthesia_type'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the categorical values contains two more levels and the variable does not follow some natural order, such as 'marital_status', we cannot simlply use 0,1,2 to replace each level. One common way to process is that for each level of a variable, we make it as extra feature and consider the presence and absence of that feature. Let's see the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---before transformation---\n",
      "0    DIVORCED\n",
      "1     MARRIED\n",
      "2     MARRIED\n",
      "3     MARRIED\n",
      "4      SINGLE\n",
      "Name: marital_status, dtype: object\n",
      "---after transformation---\n",
      "   DIVORCED  MARRIED  MISSING  SINGLE\n",
      "0         1        0        0       0\n",
      "1         0        1        0       0\n",
      "2         0        1        0       0\n",
      "3         0        1        0       0\n",
      "4         0        0        0       1\n"
     ]
    }
   ],
   "source": [
    "print('---before transformation---')\n",
    "print(df['marital_status'].head())\n",
    "marital_status_transformed = pd.get_dummies(df['marital_status'])\n",
    "print('---after transformation---')\n",
    "print(marital_status_transformed.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have briefly introduced the phase 'data extraction and processing' and are going to the develop ML models for our prediction task. To simplify our project, a processed data file has been provided. Let's load it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   patient_id  sex  ethnicity      race  language  marital_status  \\\n",
      "0           0    0  -1.796259 -1.657746         1       -1.605578   \n",
      "1           1    1  -1.796259 -1.827618         1       -1.801145   \n",
      "2           2    0  -1.796259 -1.827618         1       -1.801145   \n",
      "3           3    1  -1.796259 -1.827618         1       -1.801145   \n",
      "4           4    1  -1.796259 -1.827618         1       -1.924585   \n",
      "\n",
      "   smoking_status    county  attend_doc  sched_room  ...  serum_ca_min_0_7  \\\n",
      "0       -2.021878 -1.467852   -2.074528   -2.480968  ...               9.1   \n",
      "1       -1.771219 -1.860752   -2.464866   -2.700371  ...               8.6   \n",
      "2       -2.021878 -2.078109   -2.546061   -2.055911  ...              10.0   \n",
      "3       -1.686798 -2.078109   -1.334699   -1.326118  ...               8.7   \n",
      "4       -2.021878 -1.847705   -1.945910   -2.324189  ...               8.7   \n",
      "\n",
      "   serum_ca_max_0_7  serum_ca_avg_0_7  serum_ca_var_0_7  count_serum_can_0_7  \\\n",
      "0               9.4          9.212500          0.000000                    0   \n",
      "1              10.0          9.300000          0.653333                    4   \n",
      "2              10.0         10.000000          0.000000                    2   \n",
      "3              10.3          9.233333          0.282424                   12   \n",
      "4               9.6          9.025000          0.139286                    8   \n",
      "\n",
      "   serum_anion_gap_avg_0_7  count_serum_anion_gapn_0_7  ckd        egfr  \\\n",
      "0                12.333333                           0    1   94.040797   \n",
      "1                 9.000000                           2    1   95.500156   \n",
      "2                 7.000000                           1    1   94.040797   \n",
      "3                 8.500000                           6    1   89.149118   \n",
      "4                12.600000                           5    1  120.954389   \n",
      "\n",
      "   aki_surg_disch  \n",
      "0             0.0  \n",
      "1             0.0  \n",
      "2             0.0  \n",
      "3             1.0  \n",
      "4             0.0  \n",
      "\n",
      "[5 rows x 139 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('processed_data.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Feature Scaling\n",
    "\n",
    "The dataset often contains different types of variables and the range of the variables may differ a lot. Let's check two variables in our dataset, such as 'serum_creatinine_min_0_7' and 'serum_anion_gap_avg_0_7'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    10000.000000\n",
      "mean         0.946957\n",
      "std          0.402052\n",
      "min          0.200000\n",
      "25%          0.800000\n",
      "50%          0.885000\n",
      "75%          0.980000\n",
      "max          9.050000\n",
      "Name: serum_creatinine_avg_0_7, dtype: float64\n",
      "count    10000.000000\n",
      "mean        10.801996\n",
      "std          2.453134\n",
      "min          2.000000\n",
      "25%          9.000000\n",
      "50%         11.000000\n",
      "75%         12.333333\n",
      "max         24.000000\n",
      "Name: serum_anion_gap_avg_0_7, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['serum_creatinine_avg_0_7'].describe())\n",
    "print(df['serum_anion_gap_avg_0_7'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the original scale, the model may put more weight on the variables with a large scale. Thus the performance of model might go down. In order to deal with this problem, we need to apply the technique of feature scaling to make sure features are on almost the same scale.\n",
    "\n",
    "Notice that not all ML models require feature scaling. ML algorithms like linear regression, logistic regression, neural network, PCA (principal component analysis), etc., require data to be scaled. Tree based ML algorithms like random forest, decision tree, extreme gradient boosting often don't require feature scaling.  \n",
    "\n",
    "Two frequently used feature scaling approaches are **Z-score normalization** and **Min-Max normalization**. Applying Z-score normalization will rescale the variable to have a **mean of zero** and a **standard deviation of one**. The Min-Max scaling will rescale the variable to a **fixed range, usually 0-1**. \n",
    "\n",
    "\n",
    "We will be using some data processing functions from the library scikit-learn.\n",
    "\n",
    "* Scikit-learn is an open source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fitting, data preprocessing, model selection, model evaluation, and many other utilities. (https://scikit-learn.org/stable/getting_started.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean [-2.80664381e-17 -6.68265443e-16  7.21058768e-15 -1.30739863e-16\n",
      " -2.07620587e-15 -6.06448225e-16  1.50492951e-15 -5.75539616e-17\n",
      " -2.33058017e-16 -1.27897692e-17  3.99502653e-16  9.23705556e-18\n",
      "  7.10542736e-17  7.81597009e-18  1.02318154e-16  4.81037432e-16\n",
      " -5.22959454e-15  2.34479103e-17  1.07647224e-16 -2.28439490e-16\n",
      " -6.75015599e-17 -5.68434189e-17 -2.94875235e-17  5.71986902e-16\n",
      " -1.70530257e-17  2.95656832e-15  2.55795385e-17 -1.20081722e-16\n",
      " -1.92557081e-16 -8.73967565e-17  1.00897068e-16 -2.13162821e-17\n",
      "  1.13686838e-17  1.08002496e-16 -1.70530257e-17  8.10018719e-17\n",
      "  7.81597009e-18 -2.06057393e-17  3.55271368e-17  6.39488462e-18\n",
      "  6.60804744e-17 -2.13162821e-18 -7.38964445e-17 -7.81597009e-18\n",
      "  3.87245791e-17  4.76063633e-17 -1.27897692e-17 -8.17124146e-18\n",
      "  3.41060513e-17 -1.42108547e-18 -2.77111667e-17  2.34479103e-17\n",
      "  4.47641924e-17 -4.76063633e-17  7.46069873e-18  3.12638804e-17\n",
      "  3.90798505e-17 -6.65245636e-17 -6.35935749e-17 -2.34479103e-17\n",
      "  2.48689958e-18  4.12825329e-16  1.11555210e-16  1.67688086e-16\n",
      " -4.44089210e-17 -4.47641924e-17 -3.39639428e-16  1.11270992e-15\n",
      " -8.43662917e-15  1.29452005e-14  2.52242671e-17  5.55644419e-16\n",
      "  6.94910796e-16  2.57927013e-16 -1.89004368e-16 -2.06057393e-17\n",
      " -1.09423581e-16  1.72590831e-15  1.17807986e-15 -8.88178420e-18\n",
      " -2.37321274e-16 -4.74642547e-16  1.30739863e-16 -4.79616347e-17\n",
      "  1.13686838e-17  1.07593934e-15 -1.95399252e-18  2.06554773e-15\n",
      "  4.84590146e-16  7.10542736e-19  9.78772619e-17 -3.10933501e-15\n",
      " -6.12772055e-15 -1.84030569e-15  2.55795385e-16  0.00000000e+00\n",
      " -1.80477855e-16  3.16902060e-16 -1.37845291e-16  6.75015599e-17\n",
      " -2.06057393e-16 -3.76587650e-17 -5.93658456e-16 -4.58300065e-17\n",
      " -8.45545856e-17  1.43174361e-16  2.74269496e-16  1.42108547e-18\n",
      " -3.21520588e-17 -5.40012479e-17 -1.29318778e-16  1.35003120e-16\n",
      "  1.10134124e-17 -1.13686838e-17  5.09885467e-15  4.00302014e-15\n",
      "  1.20792265e-17 -3.35020900e-16 -3.65929509e-17 -1.04307674e-15\n",
      "  1.45945478e-15  1.81188398e-16 -3.90798505e-18 -5.81934501e-16\n",
      "  3.35376171e-16  5.42144107e-16 -2.48689958e-16 -3.19744231e-17\n",
      "  3.55555585e-15 -5.69855274e-15  9.91917659e-16  4.12114787e-17\n",
      " -2.70006240e-17  6.75015599e-17 -3.23296945e-17  1.06581410e-16\n",
      "  6.44462261e-16]\n",
      "standard deviation [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "##split dataset into features (X) and labels (Y)\n",
    "X = df[df.columns.tolist()[1:-1]].values\n",
    "Y = df['aki_surg_disch'].values\n",
    "\n",
    "##z-score normalization on features\n",
    "#init the scaler\n",
    "scaler = StandardScaler()\n",
    "#fit the scaler to the data\n",
    "scaler.fit(X)\n",
    "X_normalized = scaler.transform(X)\n",
    "\n",
    "#check the mean and standard deviation of all variables, should be 0 and 1 respectively\n",
    "print('mean', np.mean(X_normalized, axis=0))\n",
    "print('standard deviation', np.std(X_normalized, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's play with Min-Max normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min value [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "max value [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "##min-max normalization on features\n",
    "#init the scaler\n",
    "scaler = MinMaxScaler()\n",
    "#fit the scaler to the data\n",
    "scaler.fit(X)\n",
    "X_minmax_normalized = scaler.transform(X)\n",
    "\n",
    "#check the min and max value of all variables, should be 0 and 1 respectively. \n",
    "print('min value', np.min(X_minmax_normalized, axis=0))\n",
    "print('max value', np.max(X_minmax_normalized, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ML Model development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will develop two ML models. One is a conventional but effective machine learning model, extreme gradient boosting (XGBoost). Another one is a simple deep learning model, multi-layer perceptron (MLP)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before digging into the model developing, we will first divide our dataset into a training set (sometimes referred to as a development set), and a testing set (sometimes referred to as a validation set). Split dataset into a training set and a testing set. Here we use a random 20% of samples as our testing set to evaluate model performance. We will also set an (optional) random state for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape:  (8000, 137)\n",
      "Test set shape:  (2000, 137)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, Y, test_size=0.20, random_state=1)\n",
    "print(\"Train set shape: \", X_train.shape)\n",
    "print(\"Test set shape: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 XGBoost model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start developing our XGBoost model. We will train our model using training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "#Init classifier\n",
    "xgb_cl = xgb.XGBClassifier()\n",
    "\n",
    "\n",
    "#Fit the model to training dataset\n",
    "xgb_cl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is trained, we need to evaluate the performance of model on testing dataset. We first need to use our model to predict the outcome and compare the prediction with ground truth.Since our outcome is binary (0/1), for each of 2000 test samples, two values will be generated. For example, (0.7,0.3) means that the patient will have 70% chance not to develop postoperative AKI, and 30% chance to develop postoperative AKI. The class that have larger probability will be selected as the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 2)\n",
      "[[0.99167347 0.00832656]\n",
      " [0.9913942  0.00860579]\n",
      " [0.9961532  0.00384684]\n",
      " ...\n",
      " [0.43677193 0.5632281 ]\n",
      " [0.99023664 0.00976333]\n",
      " [0.9516187  0.04838132]]\n"
     ]
    }
   ],
   "source": [
    "y_prob = xgb_cl.predict_proba(X_test)\n",
    "print(y_prob.shape)\n",
    "print(y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = np.argmax(y_prob, axis=1)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the performance of our model usin\n",
    "#### Accuracy\n",
    "It calculates ratio of number of correct predictions to the total number of input samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8475"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = sum(y_hat == y_test) / len(y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance\n",
    "\n",
    "ML model should be explainable to provide some understanding between the input features and the output. XGBoost can automatically provide estimates of feature importance from a trained predictive model. Using attribute name 'feature_importances_' we can get the feature importance score for all input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00523487 0.00465262 0.00488358 0.00562574 0.00499612 0.00562071\n",
      " 0.00458559 0.00817062 0.00830173 0.         0.03641732 0.00674455\n",
      " 0.00655147 0.00908501 0.01049678 0.00487934 0.00511769 0.00988179\n",
      " 0.01279844 0.00585523 0.00707159 0.00670204 0.00712389 0.00540621\n",
      " 0.00584235 0.00845196 0.00846781 0.00628176 0.00611165 0.0061715\n",
      " 0.00601843 0.00321217 0.0049367  0.01053559 0.00737355 0.00231154\n",
      " 0.         0.00136139 0.00655475 0.004007   0.00410873 0.00402686\n",
      " 0.00654819 0.00699738 0.00387213 0.01250133 0.00628857 0.00360613\n",
      " 0.0033693  0.00577783 0.00696724 0.00671653 0.02040027 0.0062748\n",
      " 0.00595305 0.00536856 0.00997729 0.00599094 0.00805699 0.008273\n",
      " 0.0054919  0.00626372 0.00586068 0.00581319 0.00620992 0.007451\n",
      " 0.01131509 0.01362963 0.         0.         0.         0.01440156\n",
      " 0.00669511 0.00870439 0.00518164 0.01037926 0.00861936 0.00542083\n",
      " 0.00861842 0.0091252  0.00706168 0.0069644  0.007368   0.00661351\n",
      " 0.01355573 0.00499858 0.00946412 0.01300297 0.00611423 0.00454162\n",
      " 0.00538655 0.00521091 0.00672099 0.00691427 0.00855996 0.0066042\n",
      " 0.00641349 0.00892474 0.00693326 0.00628289 0.00599974 0.00575655\n",
      " 0.00644066 0.00427624 0.00469923 0.00718788 0.00671722 0.00429898\n",
      " 0.00972086 0.0063966  0.03060299 0.01358003 0.00818592 0.00690753\n",
      " 0.00385654 0.00600814 0.02465178 0.0088198  0.02206636 0.00647972\n",
      " 0.00757839 0.00686432 0.         0.01080106 0.00872463 0.00982816\n",
      " 0.00608461 0.00413648 0.01390718 0.00521291 0.0088549  0.00866613\n",
      " 0.         0.00502264 0.         0.0017983  0.00813429]\n"
     ]
    }
   ],
   "source": [
    "print(xgb_cl.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's list top 20 features and their scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='feature_name'>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_names = df.columns.tolist()[1:-1]\n",
    "feature_importance_df = pd.DataFrame({'feature_name' : feature_names, 'importance_score' : xgb_cl.feature_importances_})\n",
    "\n",
    "###sort the feature importance\n",
    "feature_importance_df = feature_importance_df.sort_values(['importance_score'])\n",
    "top_20_features = feature_importance_df.tail(20)\n",
    "top_20_features.plot.barh(x='feature_name', y='importance_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observed that the top 5 features including the scheduled primary procedure code, some laboratory measurements with 0-7 days before surgery start time (i.e., serum creatinine, serum sodium and serum potassium) and hypertension comorbidity contribute most to the model prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 MLP model\n",
    "We will use Keras to create a fully-connected neural network for our prediction task. This type of deep learning architecture is sometimes also known as a multi-layer perceptron (MLP). It is a relatively simple deep learning model that passes input data through multiple hidden layers (each with a number of hidden neurons and a particular activation function) to produce an output (see figure below). We will construct our model to perform a classification task from our dataset.\n",
    "<img src=\"ANN.jpg\" alt=\"ANN\" width=\"600\" height=\"600\">\n",
    "\n",
    "There are many ways to create a model using the Keras API. Here, we will create a Sequential object, which is a way to define a series of layers that make up our model. In a Sequential model, input data will flow from one layer to the next, in the order that we define our layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "executionInfo": {
     "elapsed": 4016,
     "status": "ok",
     "timestamp": 1654527395770,
     "user": {
      "displayName": "Benjamin Shickel",
      "userId": "07487924651552066401"
     },
     "user_tz": 240
    },
    "id": "BG5sFXLvsi5B"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each hidden layer of our neural network will be created using the **Dense** class from Keras. For each layer, we must define the number of hidden units (also known as neurons). There are several optional arguments we may also pass, which can be viewed in the [Keras documentation page](https://keras.io/api/layers/core_layers/dense/). We can add many layers to our deep learning model using the .add() function of the Sequential class. You can think of a Sequential container as a list of hidden layers.\n",
    "\n",
    "For the first layer of our neural network, we must tell Keras how many variables to expect in each input vector. From our previous data exploration, we know that each patient is defined by 137 different variables, so the input dimension to our network is 137.\n",
    "\n",
    "One reason why deep learning models are so powerful is their ability to model complex variable interactions through nonlinear activation functions. We have several choices for activation function. In our example, we will use the commonly chosen Rectified Linear Unit activation (ReLU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(units=500, input_dim=137, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far our model has a single hidden layer. Let's add one more hidden layer with 800 hidden units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(units=800, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we are satisfied with the hidden layers of our model, we need to add an output layer for generating class predictions. Our output layer will also be a Dense layer, but it will only have a single (1) unit. Instead of ReLU, we will use a sigmoid activation function, which is typically chosen for binary classification problems such as ours. Using a sigmoid activation on our output layer allows us to interpret the output as a prediction probability. In other words, the probability that a given input vector belongs to class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined the architecture of our neural network, we will use the .compile() function to build it. In our example we are defining a few arguments that are associated with the training of our model:\n",
    "* We are using a binary cross-entropy loss. This is an appropriate choise for binary classification.\n",
    "* We will be using the Adam optimizer, which is a popular version of stochastic gradient descent (SGD).\n",
    "* For this example, we are interested in our model's prediction accuracy, so we'll tell Keras to use the \"accuracy\" metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to train our prediction model! We will fit the model using our training dataset. We will use the one-line function **.fit()** to train our entire deep learning model.\n",
    "\n",
    "* We will tell Keras to train the model for 10 epochs.\n",
    "* We will use a batch size of 64 samples. During each epoch, the model will pass in 64 samples at a time.\n",
    "* We will use a random 30% of the training dataset as our hold-out dataset (here called the validation set) for computing metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "ez-TWmw5uGNT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "88/88 [==============================] - 11s 78ms/step - loss: 0.3920 - accuracy: 0.8389 - val_loss: 0.3845 - val_accuracy: 0.8338\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 7s 77ms/step - loss: 0.3316 - accuracy: 0.8632 - val_loss: 0.3726 - val_accuracy: 0.8367\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 7s 79ms/step - loss: 0.2896 - accuracy: 0.8855 - val_loss: 0.3760 - val_accuracy: 0.8433\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 6s 71ms/step - loss: 0.2446 - accuracy: 0.9030 - val_loss: 0.3908 - val_accuracy: 0.8342\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 6s 73ms/step - loss: 0.2019 - accuracy: 0.9239 - val_loss: 0.4537 - val_accuracy: 0.8146\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 0.1620 - accuracy: 0.9366 - val_loss: 0.4860 - val_accuracy: 0.8358\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 0.1116 - accuracy: 0.9611 - val_loss: 0.5357 - val_accuracy: 0.8163\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 0.0735 - accuracy: 0.9759 - val_loss: 0.6414 - val_accuracy: 0.8196\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 0.0772 - accuracy: 0.9714 - val_loss: 0.6194 - val_accuracy: 0.8042\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 6s 70ms/step - loss: 0.0606 - accuracy: 0.9796 - val_loss: 0.6768 - val_accuracy: 0.8204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f59edae9f40>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split= 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 211,
     "status": "ok",
     "timestamp": 1654527396881,
     "user": {
      "displayName": "Benjamin Shickel",
      "userId": "07487924651552066401"
     },
     "user_tz": 240
    },
    "id": "wqFjAlvrlK2R"
   },
   "source": [
    "Let's check the performance of our trained model on the test set we already created. The model has never seen this particular data, so it can provide an idea of how well the model might perform in the future (generalizability to unseen data). We will use the Keras function .evaluate(), which will compute the loss, as well as any metrics we defined when compiling our model. Since we told Keras to use \"accuracy\" when we compiled, we will see the model's accuracy on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 22ms/step - loss: 0.6830 - accuracy: 0.8235\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gH0MMpYJuMl9"
   },
   "source": [
    "Let's try another neural network! We will have three hidden layers with hidden units 500, 800 and 1000 respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "executionInfo": {
     "elapsed": 595,
     "status": "ok",
     "timestamp": 1654527402669,
     "user": {
      "displayName": "Benjamin Shickel",
      "userId": "07487924651552066401"
     },
     "user_tz": 240
    },
    "id": "oAyRynnCyc9L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "88/88 [==============================] - 17s 167ms/step - loss: 0.3956 - accuracy: 0.8366 - val_loss: 0.3791 - val_accuracy: 0.8388\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 12s 139ms/step - loss: 0.3309 - accuracy: 0.8627 - val_loss: 0.4008 - val_accuracy: 0.8367\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 12s 136ms/step - loss: 0.2967 - accuracy: 0.8773 - val_loss: 0.3993 - val_accuracy: 0.8217\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 12s 137ms/step - loss: 0.2431 - accuracy: 0.9038 - val_loss: 0.4352 - val_accuracy: 0.8346\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 14s 154ms/step - loss: 0.1989 - accuracy: 0.9205 - val_loss: 0.5105 - val_accuracy: 0.8021\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 12s 133ms/step - loss: 0.1368 - accuracy: 0.9482 - val_loss: 0.6352 - val_accuracy: 0.8221\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 11s 131ms/step - loss: 0.1104 - accuracy: 0.9623 - val_loss: 0.6337 - val_accuracy: 0.8388\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 0.0902 - accuracy: 0.9650 - val_loss: 0.7095 - val_accuracy: 0.8267\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 12s 136ms/step - loss: 0.0622 - accuracy: 0.9762 - val_loss: 0.8576 - val_accuracy: 0.8112\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 13s 149ms/step - loss: 0.0493 - accuracy: 0.9818 - val_loss: 0.8720 - val_accuracy: 0.8246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f59ed9791f0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "###first hidden layer with 500 hidden units, input layer with 137 variables as input\n",
    "model.add(layers.Dense(units=500, input_dim=137, activation='relu'))\n",
    "###second hidden layer with 800 hidden units\n",
    "model.add(layers.Dense(units=800, activation='relu'))\n",
    "###Third hidden layer with 1000 hidden units\n",
    "###To do, add third hidden layer with 1000 hidden units\n",
    "model.add(layers.Dense(units=1000, activation='relu')) #New\n",
    "###last output layer\n",
    "model.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "##compile and train the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split= 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yD6lUNBwy-tB"
   },
   "source": [
    "Evaluate the performance of new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1654527402670,
     "user": {
      "displayName": "Benjamin Shickel",
      "userId": "07487924651552066401"
     },
     "user_tz": 240
    },
    "id": "s5E3HV1My-HZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 2s 32ms/step - loss: 0.8217 - accuracy: 0.8325\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "MLP-Teacher.ipynb",
   "provenance": [
    {
     "file_id": "1HeKPEhTAMN0YCDHRP9wcYv18UUaaOJQW",
     "timestamp": 1654466786319
    },
    {
     "file_id": "148jGrKocKC_DFagQW4JBd7jtGQnOR9yf",
     "timestamp": 1654462810571
    }
   ],
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
